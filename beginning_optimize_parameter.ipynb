{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter: 모델 최적화 과정을 제어할 수 있는 조절 가능한 매개변수\n",
    "- epoch: 데이터셋을 반복하는 횟수\n",
    "- batch size: 매개변수가 갱신되기 전 신경망을 통해 전파된 데이터 샘플의 수\n",
    "- learning rate: 값이 작을수록 학습 속도가 느려지고, 값이 크면 학습 중 예측할 수 없는 동작이 발생할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization Loop\n",
    "- train loop: 학습용 데이터셋을 반복하고 최적의 매개변수로 수렴\n",
    "- validation, test loop: 모델 성능이 개선되고 있는지를 확인하기 위해 테스트 데이터셋을 반복함\n",
    "\n",
    "### Loss function\n",
    "- 획득한 결과와 실제 값 사이의 틀린 정도를 측정, 학습 중에 이 값을 최소화하는 방향으로 진행, 예측과 label을 비교하여 loss 계산\n",
    "    + MSE: regression task에 사용\n",
    "    + NLL (Negative Log Likelihood): classification에 사용\n",
    "    + CrossEntropyLoss (LogSoftmax와 NLL 합침)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    \n",
    "    for batch, (X,y) in enumerate(dataloader):\n",
    "        # calculate prediction and loss\n",
    "        pred =model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        # backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch*len(X)\n",
    "            print(f\"loss: {loss:>.7f} [{current:>5d}/{size:>5d}\")\n",
    "            \n",
    "            \n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches =len(dataloader)\n",
    "    \n",
    "    test_loss, correct = 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1)==y).type(torch.float).sum().item()\n",
    "            \n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    \n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------\n",
      "loss: 2.3058732 [    0/60000\n",
      "loss: 2.2969346 [ 6400/60000\n",
      "loss: 2.2736914 [12800/60000\n",
      "loss: 2.2686176 [19200/60000\n",
      "loss: 2.2467835 [25600/60000\n",
      "loss: 2.2228527 [32000/60000\n",
      "loss: 2.2221441 [38400/60000\n",
      "loss: 2.1955137 [44800/60000\n",
      "loss: 2.2006226 [51200/60000\n",
      "loss: 2.1602459 [57600/60000\n",
      "Test Error: \n",
      " Accuracy: 46.0%, Avg loss: 2.158386 \n",
      "\n",
      "Epoch 2\n",
      "-------------------\n",
      "loss: 2.1719401 [    0/60000\n",
      "loss: 2.1615202 [ 6400/60000\n",
      "loss: 2.1090696 [12800/60000\n",
      "loss: 2.1241095 [19200/60000\n",
      "loss: 2.0640786 [25600/60000\n",
      "loss: 2.0159433 [32000/60000\n",
      "loss: 2.0339916 [38400/60000\n",
      "loss: 1.9647261 [44800/60000\n",
      "loss: 1.9733983 [51200/60000\n",
      "loss: 1.8974938 [57600/60000\n",
      "Test Error: \n",
      " Accuracy: 57.2%, Avg loss: 1.896677 \n",
      "\n",
      "Epoch 3\n",
      "-------------------\n",
      "loss: 1.9298425 [    0/60000\n",
      "loss: 1.8981118 [ 6400/60000\n",
      "loss: 1.7915467 [12800/60000\n",
      "loss: 1.8311719 [19200/60000\n",
      "loss: 1.7081628 [25600/60000\n",
      "loss: 1.6745000 [32000/60000\n",
      "loss: 1.6891218 [38400/60000\n",
      "loss: 1.5961089 [44800/60000\n",
      "loss: 1.6179245 [51200/60000\n",
      "loss: 1.5176457 [57600/60000\n",
      "Test Error: \n",
      " Accuracy: 60.6%, Avg loss: 1.532650 \n",
      "\n",
      "Epoch 4\n",
      "-------------------\n",
      "loss: 1.5975579 [    0/60000\n",
      "loss: 1.5607405 [ 6400/60000\n",
      "loss: 1.4188893 [12800/60000\n",
      "loss: 1.4904292 [19200/60000\n",
      "loss: 1.3619807 [25600/60000\n",
      "loss: 1.3689674 [32000/60000\n",
      "loss: 1.3755031 [38400/60000\n",
      "loss: 1.3038167 [44800/60000\n",
      "loss: 1.3342718 [51200/60000\n",
      "loss: 1.2436148 [57600/60000\n",
      "Test Error: \n",
      " Accuracy: 62.9%, Avg loss: 1.265331 \n",
      "\n",
      "Epoch 5\n",
      "-------------------\n",
      "loss: 1.3417187 [    0/60000\n",
      "loss: 1.3206629 [ 6400/60000\n",
      "loss: 1.1611341 [12800/60000\n",
      "loss: 1.2672427 [19200/60000\n",
      "loss: 1.1358757 [25600/60000\n",
      "loss: 1.1676807 [32000/60000\n",
      "loss: 1.1819794 [38400/60000\n",
      "loss: 1.1208736 [44800/60000\n",
      "loss: 1.1571523 [51200/60000\n",
      "loss: 1.0835391 [57600/60000\n",
      "Test Error: \n",
      " Accuracy: 64.3%, Avg loss: 1.098553 \n",
      "\n",
      "Epoch 6\n",
      "-------------------\n",
      "loss: 1.1701996 [    0/60000\n",
      "loss: 1.1681138 [ 6400/60000\n",
      "loss: 0.9915765 [12800/60000\n",
      "loss: 1.1279812 [19200/60000\n",
      "loss: 0.9953940 [25600/60000\n",
      "loss: 1.0328604 [32000/60000\n",
      "loss: 1.0633110 [38400/60000\n",
      "loss: 1.0044557 [44800/60000\n",
      "loss: 1.0418378 [51200/60000\n",
      "loss: 0.9843280 [57600/60000\n",
      "Test Error: \n",
      " Accuracy: 65.4%, Avg loss: 0.990913 \n",
      "\n",
      "Epoch 7\n",
      "-------------------\n",
      "loss: 1.0507768 [    0/60000\n",
      "loss: 1.0690753 [ 6400/60000\n",
      "loss: 0.8756695 [12800/60000\n",
      "loss: 1.0349349 [19200/60000\n",
      "loss: 0.9066275 [25600/60000\n",
      "loss: 0.9385569 [32000/60000\n",
      "loss: 0.9858207 [38400/60000\n",
      "loss: 0.9290841 [44800/60000\n",
      "loss: 0.9622703 [51200/60000\n",
      "loss: 0.9179575 [57600/60000\n",
      "Test Error: \n",
      " Accuracy: 66.5%, Avg loss: 0.917659 \n",
      "\n",
      "Epoch 8\n",
      "-------------------\n",
      "loss: 0.9636126 [    0/60000\n",
      "loss: 1.0004126 [ 6400/60000\n",
      "loss: 0.7931986 [12800/60000\n",
      "loss: 0.9687378 [19200/60000\n",
      "loss: 0.8470526 [25600/60000\n",
      "loss: 0.8697823 [32000/60000\n",
      "loss: 0.9312096 [38400/60000\n",
      "loss: 0.8788336 [44800/60000\n",
      "loss: 0.9048814 [51200/60000\n",
      "loss: 0.8698834 [57600/60000\n",
      "Test Error: \n",
      " Accuracy: 67.7%, Avg loss: 0.864951 \n",
      "\n",
      "Epoch 9\n",
      "-------------------\n",
      "loss: 0.8968499 [    0/60000\n",
      "loss: 0.9489264 [ 6400/60000\n",
      "loss: 0.7317832 [12800/60000\n",
      "loss: 0.9190716 [19200/60000\n",
      "loss: 0.8044577 [25600/60000\n",
      "loss: 0.8178509 [32000/60000\n",
      "loss: 0.8896756 [38400/60000\n",
      "loss: 0.8437473 [44800/60000\n",
      "loss: 0.8618242 [51200/60000\n",
      "loss: 0.8326738 [57600/60000\n",
      "Test Error: \n",
      " Accuracy: 68.7%, Avg loss: 0.824995 \n",
      "\n",
      "Epoch 10\n",
      "-------------------\n",
      "loss: 0.8434315 [    0/60000\n",
      "loss: 0.9077376 [ 6400/60000\n",
      "loss: 0.6839688 [12800/60000\n",
      "loss: 0.8802428 [19200/60000\n",
      "loss: 0.7721720 [25600/60000\n",
      "loss: 0.7776183 [32000/60000\n",
      "loss: 0.8561619 [38400/60000\n",
      "loss: 0.8179553 [44800/60000\n",
      "loss: 0.8281070 [51200/60000\n",
      "loss: 0.8026301 [57600/60000\n",
      "Test Error: \n",
      " Accuracy: 70.0%, Avg loss: 0.793207 \n",
      "\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}\\n-------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "09984021b85b4fc73470db0c076536dd43f155500b22647bf3eda11468cba887"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
