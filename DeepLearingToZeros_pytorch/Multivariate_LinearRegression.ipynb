{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.FloatTensor([[1],[2],[3]])\n",
    "y_train = torch.FloatTensor([[1],[2],[3]])\n",
    "\n",
    "W = torch.zeros(1, requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "\n",
    "optimizer = optim.SGD([W,b], lr=0.01)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    hypothesis = W*X_train + b\n",
    "\n",
    "    loss = torch.mean((hypothesis - y_train)**2)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    0/100, hypothesis: tensor([0., 0., 0., 0., 0.]), loss: 1.360865\n",
      "Epoch:    1/100, hypothesis: tensor([-5.5445e-05,  1.7618e-07, -4.2241e-05, -5.3666e-05,  1.9912e-05]), loss: 1.360790\n",
      "Epoch:    2/100, hypothesis: tensor([-1.1089e-04,  3.5256e-07, -8.4480e-05, -1.0733e-04,  3.9823e-05]), loss: 1.360715\n",
      "Epoch:    3/100, hypothesis: tensor([-1.6633e-04,  5.2913e-07, -1.2672e-04, -1.6099e-04,  5.9733e-05]), loss: 1.360640\n",
      "Epoch:    4/100, hypothesis: tensor([-2.2176e-04,  7.0588e-07, -1.6895e-04, -2.1465e-04,  7.9643e-05]), loss: 1.360564\n",
      "Epoch:    5/100, hypothesis: tensor([-2.7720e-04,  8.8284e-07, -2.1118e-04, -2.6831e-04,  9.9551e-05]), loss: 1.360489\n",
      "Epoch:    6/100, hypothesis: tensor([-3.3263e-04,  1.0600e-06, -2.5341e-04, -3.2197e-04,  1.1946e-04]), loss: 1.360414\n",
      "Epoch:    7/100, hypothesis: tensor([-3.8806e-04,  1.2373e-06, -2.9564e-04, -3.7562e-04,  1.3937e-04]), loss: 1.360339\n",
      "Epoch:    8/100, hypothesis: tensor([-4.4349e-04,  1.4148e-06, -3.3787e-04, -4.2927e-04,  1.5927e-04]), loss: 1.360264\n",
      "Epoch:    9/100, hypothesis: tensor([-4.9891e-04,  1.5926e-06, -3.8009e-04, -4.8292e-04,  1.7918e-04]), loss: 1.360189\n",
      "Epoch:   10/100, hypothesis: tensor([-5.5433e-04,  1.7705e-06, -4.2232e-04, -5.3657e-04,  1.9909e-04]), loss: 1.360114\n",
      "Epoch:   11/100, hypothesis: tensor([-6.0975e-04,  1.9486e-06, -4.6454e-04, -5.9021e-04,  2.1899e-04]), loss: 1.360039\n",
      "Epoch:   12/100, hypothesis: tensor([-6.6517e-04,  2.1270e-06, -5.0676e-04, -6.4385e-04,  2.3889e-04]), loss: 1.359963\n",
      "Epoch:   13/100, hypothesis: tensor([-7.2058e-04,  2.3054e-06, -5.4897e-04, -6.9749e-04,  2.5880e-04]), loss: 1.359888\n",
      "Epoch:   14/100, hypothesis: tensor([-7.7599e-04,  2.4841e-06, -5.9119e-04, -7.5113e-04,  2.7870e-04]), loss: 1.359813\n",
      "Epoch:   15/100, hypothesis: tensor([-8.3140e-04,  2.6630e-06, -6.3340e-04, -8.0476e-04,  2.9860e-04]), loss: 1.359738\n",
      "Epoch:   16/100, hypothesis: tensor([-8.8681e-04,  2.8421e-06, -6.7561e-04, -8.5840e-04,  3.1850e-04]), loss: 1.359663\n",
      "Epoch:   17/100, hypothesis: tensor([-9.4222e-04,  3.0213e-06, -7.1782e-04, -9.1203e-04,  3.3840e-04]), loss: 1.359588\n",
      "Epoch:   18/100, hypothesis: tensor([-9.9762e-04,  3.2008e-06, -7.6003e-04, -9.6566e-04,  3.5830e-04]), loss: 1.359513\n",
      "Epoch:   19/100, hypothesis: tensor([-1.0530e-03,  3.3804e-06, -8.0223e-04, -1.0193e-03,  3.7820e-04]), loss: 1.359438\n",
      "Epoch:   20/100, hypothesis: tensor([-1.1084e-03,  3.5602e-06, -8.4443e-04, -1.0729e-03,  3.9810e-04]), loss: 1.359363\n",
      "Epoch:   21/100, hypothesis: tensor([-1.1638e-03,  3.7403e-06, -8.8664e-04, -1.1265e-03,  4.1800e-04]), loss: 1.359288\n",
      "Epoch:   22/100, hypothesis: tensor([-1.2192e-03,  3.9205e-06, -9.2883e-04, -1.1802e-03,  4.3790e-04]), loss: 1.359213\n",
      "Epoch:   23/100, hypothesis: tensor([-1.2746e-03,  4.1010e-06, -9.7103e-04, -1.2338e-03,  4.5779e-04]), loss: 1.359138\n",
      "Epoch:   24/100, hypothesis: tensor([-1.3300e-03,  4.2816e-06, -1.0132e-03, -1.2874e-03,  4.7769e-04]), loss: 1.359062\n",
      "Epoch:   25/100, hypothesis: tensor([-1.3854e-03,  4.4624e-06, -1.0554e-03, -1.3410e-03,  4.9758e-04]), loss: 1.358988\n",
      "Epoch:   26/100, hypothesis: tensor([-1.4407e-03,  4.6434e-06, -1.0976e-03, -1.3946e-03,  5.1748e-04]), loss: 1.358912\n",
      "Epoch:   27/100, hypothesis: tensor([-1.4961e-03,  4.8246e-06, -1.1398e-03, -1.4482e-03,  5.3737e-04]), loss: 1.358837\n",
      "Epoch:   28/100, hypothesis: tensor([-1.5515e-03,  5.0060e-06, -1.1820e-03, -1.5018e-03,  5.5726e-04]), loss: 1.358763\n",
      "Epoch:   29/100, hypothesis: tensor([-1.6069e-03,  5.1875e-06, -1.2242e-03, -1.5554e-03,  5.7716e-04]), loss: 1.358687\n",
      "Epoch:   30/100, hypothesis: tensor([-1.6622e-03,  5.3694e-06, -1.2664e-03, -1.6090e-03,  5.9705e-04]), loss: 1.358612\n",
      "Epoch:   31/100, hypothesis: tensor([-1.7176e-03,  5.5512e-06, -1.3085e-03, -1.6626e-03,  6.1694e-04]), loss: 1.358537\n",
      "Epoch:   32/100, hypothesis: tensor([-1.7730e-03,  5.7335e-06, -1.3507e-03, -1.7162e-03,  6.3683e-04]), loss: 1.358462\n",
      "Epoch:   33/100, hypothesis: tensor([-1.8283e-03,  5.9158e-06, -1.3929e-03, -1.7698e-03,  6.5672e-04]), loss: 1.358387\n",
      "Epoch:   34/100, hypothesis: tensor([-1.8837e-03,  6.0983e-06, -1.4351e-03, -1.8234e-03,  6.7661e-04]), loss: 1.358312\n",
      "Epoch:   35/100, hypothesis: tensor([-1.9391e-03,  6.2810e-06, -1.4772e-03, -1.8770e-03,  6.9649e-04]), loss: 1.358238\n",
      "Epoch:   36/100, hypothesis: tensor([-1.9944e-03,  6.4640e-06, -1.5194e-03, -1.9306e-03,  7.1638e-04]), loss: 1.358163\n",
      "Epoch:   37/100, hypothesis: tensor([-2.0498e-03,  6.6470e-06, -1.5616e-03, -1.9842e-03,  7.3627e-04]), loss: 1.358088\n",
      "Epoch:   38/100, hypothesis: tensor([-2.1051e-03,  6.8303e-06, -1.6037e-03, -2.0378e-03,  7.5615e-04]), loss: 1.358013\n",
      "Epoch:   39/100, hypothesis: tensor([-2.1605e-03,  7.0138e-06, -1.6459e-03, -2.0914e-03,  7.7604e-04]), loss: 1.357938\n",
      "Epoch:   40/100, hypothesis: tensor([-2.2158e-03,  7.1975e-06, -1.6881e-03, -2.1449e-03,  7.9592e-04]), loss: 1.357863\n",
      "Epoch:   41/100, hypothesis: tensor([-2.2712e-03,  7.3814e-06, -1.7302e-03, -2.1985e-03,  8.1581e-04]), loss: 1.357788\n",
      "Epoch:   42/100, hypothesis: tensor([-2.3265e-03,  7.5656e-06, -1.7724e-03, -2.2521e-03,  8.3569e-04]), loss: 1.357713\n",
      "Epoch:   43/100, hypothesis: tensor([-2.3818e-03,  7.7498e-06, -1.8145e-03, -2.3057e-03,  8.5557e-04]), loss: 1.357638\n",
      "Epoch:   44/100, hypothesis: tensor([-2.4372e-03,  7.9342e-06, -1.8567e-03, -2.3592e-03,  8.7546e-04]), loss: 1.357563\n",
      "Epoch:   45/100, hypothesis: tensor([-2.4925e-03,  8.1189e-06, -1.8989e-03, -2.4128e-03,  8.9534e-04]), loss: 1.357488\n",
      "Epoch:   46/100, hypothesis: tensor([-2.5478e-03,  8.3037e-06, -1.9410e-03, -2.4664e-03,  9.1522e-04]), loss: 1.357413\n",
      "Epoch:   47/100, hypothesis: tensor([-2.6032e-03,  8.4887e-06, -1.9832e-03, -2.5199e-03,  9.3510e-04]), loss: 1.357338\n",
      "Epoch:   48/100, hypothesis: tensor([-2.6585e-03,  8.6740e-06, -2.0253e-03, -2.5735e-03,  9.5498e-04]), loss: 1.357264\n",
      "Epoch:   49/100, hypothesis: tensor([-2.7138e-03,  8.8593e-06, -2.0674e-03, -2.6271e-03,  9.7485e-04]), loss: 1.357189\n",
      "Epoch:   50/100, hypothesis: tensor([-2.7691e-03,  9.0449e-06, -2.1096e-03, -2.6806e-03,  9.9473e-04]), loss: 1.357114\n",
      "Epoch:   51/100, hypothesis: tensor([-2.8245e-03,  9.2307e-06, -2.1517e-03, -2.7342e-03,  1.0146e-03]), loss: 1.357039\n",
      "Epoch:   52/100, hypothesis: tensor([-2.8798e-03,  9.4168e-06, -2.1939e-03, -2.7877e-03,  1.0345e-03]), loss: 1.356964\n",
      "Epoch:   53/100, hypothesis: tensor([-2.9351e-03,  9.6030e-06, -2.2360e-03, -2.8413e-03,  1.0544e-03]), loss: 1.356889\n",
      "Epoch:   54/100, hypothesis: tensor([-2.9904e-03,  9.7893e-06, -2.2781e-03, -2.8948e-03,  1.0742e-03]), loss: 1.356814\n",
      "Epoch:   55/100, hypothesis: tensor([-3.0457e-03,  9.9760e-06, -2.3203e-03, -2.9484e-03,  1.0941e-03]), loss: 1.356740\n",
      "Epoch:   56/100, hypothesis: tensor([-3.1010e-03,  1.0163e-05, -2.3624e-03, -3.0019e-03,  1.1140e-03]), loss: 1.356665\n",
      "Epoch:   57/100, hypothesis: tensor([-3.1563e-03,  1.0349e-05, -2.4045e-03, -3.0555e-03,  1.1339e-03]), loss: 1.356590\n",
      "Epoch:   58/100, hypothesis: tensor([-3.2116e-03,  1.0537e-05, -2.4467e-03, -3.1090e-03,  1.1537e-03]), loss: 1.356515\n",
      "Epoch:   59/100, hypothesis: tensor([-3.2669e-03,  1.0724e-05, -2.4888e-03, -3.1625e-03,  1.1736e-03]), loss: 1.356440\n",
      "Epoch:   60/100, hypothesis: tensor([-3.3222e-03,  1.0912e-05, -2.5309e-03, -3.2161e-03,  1.1935e-03]), loss: 1.356365\n",
      "Epoch:   61/100, hypothesis: tensor([-3.3775e-03,  1.1099e-05, -2.5730e-03, -3.2696e-03,  1.2133e-03]), loss: 1.356291\n",
      "Epoch:   62/100, hypothesis: tensor([-3.4328e-03,  1.1287e-05, -2.6151e-03, -3.3231e-03,  1.2332e-03]), loss: 1.356216\n",
      "Epoch:   63/100, hypothesis: tensor([-3.4881e-03,  1.1476e-05, -2.6573e-03, -3.3767e-03,  1.2531e-03]), loss: 1.356141\n",
      "Epoch:   64/100, hypothesis: tensor([-3.5434e-03,  1.1664e-05, -2.6994e-03, -3.4302e-03,  1.2729e-03]), loss: 1.356066\n",
      "Epoch:   65/100, hypothesis: tensor([-3.5987e-03,  1.1852e-05, -2.7415e-03, -3.4837e-03,  1.2928e-03]), loss: 1.355992\n",
      "Epoch:   66/100, hypothesis: tensor([-3.6539e-03,  1.2041e-05, -2.7836e-03, -3.5372e-03,  1.3127e-03]), loss: 1.355917\n",
      "Epoch:   67/100, hypothesis: tensor([-3.7092e-03,  1.2230e-05, -2.8257e-03, -3.5908e-03,  1.3325e-03]), loss: 1.355842\n",
      "Epoch:   68/100, hypothesis: tensor([-3.7645e-03,  1.2419e-05, -2.8678e-03, -3.6443e-03,  1.3524e-03]), loss: 1.355767\n",
      "Epoch:   69/100, hypothesis: tensor([-3.8198e-03,  1.2608e-05, -2.9099e-03, -3.6978e-03,  1.3723e-03]), loss: 1.355693\n",
      "Epoch:   70/100, hypothesis: tensor([-3.8750e-03,  1.2797e-05, -2.9520e-03, -3.7513e-03,  1.3921e-03]), loss: 1.355618\n",
      "Epoch:   71/100, hypothesis: tensor([-3.9303e-03,  1.2987e-05, -2.9941e-03, -3.8048e-03,  1.4120e-03]), loss: 1.355543\n",
      "Epoch:   72/100, hypothesis: tensor([-3.9856e-03,  1.3177e-05, -3.0362e-03, -3.8583e-03,  1.4319e-03]), loss: 1.355468\n",
      "Epoch:   73/100, hypothesis: tensor([-4.0408e-03,  1.3367e-05, -3.0783e-03, -3.9118e-03,  1.4517e-03]), loss: 1.355394\n",
      "Epoch:   74/100, hypothesis: tensor([-4.0961e-03,  1.3557e-05, -3.1204e-03, -3.9654e-03,  1.4716e-03]), loss: 1.355319\n",
      "Epoch:   75/100, hypothesis: tensor([-4.1513e-03,  1.3747e-05, -3.1625e-03, -4.0189e-03,  1.4914e-03]), loss: 1.355244\n",
      "Epoch:   76/100, hypothesis: tensor([-4.2066e-03,  1.3938e-05, -3.2046e-03, -4.0724e-03,  1.5113e-03]), loss: 1.355169\n",
      "Epoch:   77/100, hypothesis: tensor([-4.2619e-03,  1.4129e-05, -3.2467e-03, -4.1259e-03,  1.5312e-03]), loss: 1.355095\n",
      "Epoch:   78/100, hypothesis: tensor([-4.3171e-03,  1.4320e-05, -3.2888e-03, -4.1794e-03,  1.5510e-03]), loss: 1.355020\n",
      "Epoch:   79/100, hypothesis: tensor([-4.3724e-03,  1.4511e-05, -3.3309e-03, -4.2328e-03,  1.5709e-03]), loss: 1.354945\n",
      "Epoch:   80/100, hypothesis: tensor([-4.4276e-03,  1.4703e-05, -3.3729e-03, -4.2863e-03,  1.5907e-03]), loss: 1.354871\n",
      "Epoch:   81/100, hypothesis: tensor([-4.4828e-03,  1.4894e-05, -3.4150e-03, -4.3398e-03,  1.6106e-03]), loss: 1.354796\n",
      "Epoch:   82/100, hypothesis: tensor([-4.5381e-03,  1.5086e-05, -3.4571e-03, -4.3933e-03,  1.6304e-03]), loss: 1.354721\n",
      "Epoch:   83/100, hypothesis: tensor([-4.5933e-03,  1.5278e-05, -3.4992e-03, -4.4468e-03,  1.6503e-03]), loss: 1.354647\n",
      "Epoch:   84/100, hypothesis: tensor([-4.6486e-03,  1.5470e-05, -3.5412e-03, -4.5003e-03,  1.6702e-03]), loss: 1.354572\n",
      "Epoch:   85/100, hypothesis: tensor([-4.7038e-03,  1.5662e-05, -3.5833e-03, -4.5538e-03,  1.6900e-03]), loss: 1.354497\n",
      "Epoch:   86/100, hypothesis: tensor([-4.7590e-03,  1.5855e-05, -3.6254e-03, -4.6072e-03,  1.7099e-03]), loss: 1.354423\n",
      "Epoch:   87/100, hypothesis: tensor([-4.8142e-03,  1.6048e-05, -3.6675e-03, -4.6607e-03,  1.7297e-03]), loss: 1.354348\n",
      "Epoch:   88/100, hypothesis: tensor([-4.8695e-03,  1.6241e-05, -3.7095e-03, -4.7142e-03,  1.7496e-03]), loss: 1.354273\n",
      "Epoch:   89/100, hypothesis: tensor([-4.9247e-03,  1.6434e-05, -3.7516e-03, -4.7677e-03,  1.7694e-03]), loss: 1.354199\n",
      "Epoch:   90/100, hypothesis: tensor([-4.9799e-03,  1.6627e-05, -3.7937e-03, -4.8211e-03,  1.7893e-03]), loss: 1.354124\n",
      "Epoch:   91/100, hypothesis: tensor([-5.0351e-03,  1.6820e-05, -3.8357e-03, -4.8746e-03,  1.8091e-03]), loss: 1.354050\n",
      "Epoch:   92/100, hypothesis: tensor([-5.0903e-03,  1.7014e-05, -3.8778e-03, -4.9281e-03,  1.8290e-03]), loss: 1.353975\n",
      "Epoch:   93/100, hypothesis: tensor([-5.1456e-03,  1.7208e-05, -3.9198e-03, -4.9815e-03,  1.8488e-03]), loss: 1.353901\n",
      "Epoch:   94/100, hypothesis: tensor([-5.2008e-03,  1.7402e-05, -3.9619e-03, -5.0350e-03,  1.8687e-03]), loss: 1.353826\n",
      "Epoch:   95/100, hypothesis: tensor([-5.2560e-03,  1.7597e-05, -4.0039e-03, -5.0885e-03,  1.8885e-03]), loss: 1.353751\n",
      "Epoch:   96/100, hypothesis: tensor([-5.3112e-03,  1.7791e-05, -4.0460e-03, -5.1419e-03,  1.9083e-03]), loss: 1.353677\n",
      "Epoch:   97/100, hypothesis: tensor([-5.3664e-03,  1.7985e-05, -4.0880e-03, -5.1954e-03,  1.9282e-03]), loss: 1.353602\n",
      "Epoch:   98/100, hypothesis: tensor([-5.4216e-03,  1.8180e-05, -4.1301e-03, -5.2488e-03,  1.9480e-03]), loss: 1.353528\n",
      "Epoch:   99/100, hypothesis: tensor([-5.4768e-03,  1.8375e-05, -4.1721e-03, -5.3023e-03,  1.9679e-03]), loss: 1.353453\n"
     ]
    }
   ],
   "source": [
    "X_train = torch.FloatTensor(np.random.randn(5,3))\n",
    "y_train = torch.FloatTensor(np.random.randn(5,1))\n",
    "\n",
    "W = torch.zeros((3,1), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "optimizer = optim.SGD([W,b], lr=1e-5)\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    hypothesis = X_train.matmul(W) + b\n",
    "    \n",
    "    loss = torch.mean((hypothesis - y_train)**2)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch: {epoch:4d}/{epochs}, hypothesis: {hypothesis.squeeze().detach()}, loss: {loss.item():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultivariateLinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(3,1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultivariateLinearRegressionModel()\n",
    "\n",
    "hypothesis = model(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    0/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:    1/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:    2/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:    3/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:    4/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:    5/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:    6/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:    7/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:    8/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:    9/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   10/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   11/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   12/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   13/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   14/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   15/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   16/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   17/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   18/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   19/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   20/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   21/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   22/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   23/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   24/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   25/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   26/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   27/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   28/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   29/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   30/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   31/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   32/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   33/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   34/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   35/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   36/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   37/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   38/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   39/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   40/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   41/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   42/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   43/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   44/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   45/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   46/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   47/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   48/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   49/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   50/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   51/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   52/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   53/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   54/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   55/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   56/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   57/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   58/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   59/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   60/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   61/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   62/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   63/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   64/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   65/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   66/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   67/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   68/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   69/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   70/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   71/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   72/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   73/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   74/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   75/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   76/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   77/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   78/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   79/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   80/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   81/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   82/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   83/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   84/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   85/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   86/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   87/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   88/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   89/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   90/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   91/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   92/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   93/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   94/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   95/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   96/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   97/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   98/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n",
      "Epoch:   99/100, hypothesis: tensor([-0.3574,  0.6001,  0.0739, -1.2380,  0.2310]), loss: 0.851287\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD([W,b], lr=1e-5)\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    hypothesis = model(X_train)\n",
    "    \n",
    "    loss = F.mse_loss(hypothesis, y_train)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch: {epoch:4d}/{epochs}, hypothesis: {hypothesis.squeeze().detach()}, loss: {loss.item():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "09984021b85b4fc73470db0c076536dd43f155500b22647bf3eda11468cba887"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
